{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dheeraj\\AppData\\Local\\Temp\\ipykernel_2248\\198480446.py:9: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  return BeautifulSoup(unescape(raw_html), 'html.parser').get_text(separator=' ')\n",
      "C:\\Users\\Dheeraj\\AppData\\Local\\Temp\\ipykernel_2248\\198480446.py:9: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  return BeautifulSoup(unescape(raw_html), 'html.parser').get_text(separator=' ')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction complete. 1000 records saved to extracted_data.csv.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "from html import unescape\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_html(raw_html):\n",
    "    if raw_html:\n",
    "     \n",
    "        return BeautifulSoup(unescape(raw_html), 'html.parser').get_text(separator=' ')\n",
    "    return ''\n",
    "\n",
    "def extract_data(posts):\n",
    "    first_post = posts[0]\n",
    "    sub = clean_html(first_post.get('sub', ''))\n",
    "    com = clean_html(first_post.get('com', ''))\n",
    "    \n",
    "    if not sub.strip():\n",
    "        return None, None\n",
    "    else:\n",
    "        return sub, com\n",
    "\n",
    "\n",
    "\n",
    "input_file_path = 'pol_062016-112019_labeled.ndjson'\n",
    "output_file_path = '4chan.csv'\n",
    "\n",
    "data_count = 0\n",
    "num_data_points = 60000\n",
    "\n",
    "with open(output_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['sub', 'com']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                json_obj = json.loads(line)\n",
    "                posts = json_obj.get('posts', [])\n",
    "                if posts:  \n",
    "                    sub, com = extract_data(posts)\n",
    "                    if sub is not None and com is not None:\n",
    "                        writer.writerow({'sub': sub, 'com': com})\n",
    "                        data_count += 1\n",
    "                        if data_count >= num_data_points:\n",
    "                            break\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"JSONDecodeError encountered. Skipping invalid JSON object.\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}. Continuing to the next record.\")\n",
    "\n",
    "print(f'Data extraction complete. {data_count} records saved to {output_file_path}.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
