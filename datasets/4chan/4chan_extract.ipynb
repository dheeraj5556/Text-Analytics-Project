import json
import csv
from html import unescape
from bs4 import BeautifulSoup

def clean_html(raw_html):
    if raw_html:
     
        return BeautifulSoup(unescape(raw_html), 'html.parser').get_text(separator=' ')
    return ''

def extract_data(posts):
    first_post = posts[0]
    sub = clean_html(first_post.get('sub', ''))
    com = clean_html(first_post.get('com', ''))
    
    if not sub.strip():
        return None, None
    else:
        return sub, com



input_file_path = 'pol_062016-112019_labeled.ndjson'
output_file_path = '4chan.csv'

data_count = 0
num_data_points = 60000

with open(output_file_path, 'w', newline='', encoding='utf-8') as csvfile:
    fieldnames = ['sub', 'com']
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
    writer.writeheader()

    with open(input_file_path, 'r', encoding='utf-8') as file:
        for line in file:
            try:
                json_obj = json.loads(line)
                posts = json_obj.get('posts', [])
                if posts:  
                    sub, com = extract_data(posts)
                    if sub is not None and com is not None:
                        writer.writerow({'sub': sub, 'com': com})
                        data_count += 1
                        if data_count >= num_data_points:
                            break
            except json.JSONDecodeError:
                print("JSONDecodeError encountered. Skipping invalid JSON object.")
            except Exception as e:
                print(f"An error occurred: {e}. Continuing to the next record.")

print(f'Data extraction complete. {data_count} records saved to {output_file_path}.')

